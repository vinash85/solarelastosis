{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from autogluon.tabular import TabularPredictor\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# from autogluon.tabular import TabularPredictor\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# from sklearn.preprocessing import label_binarize\n",
    "# from autogluon.core.metrics import make_scorer\n",
    "\n",
    "# def custom_roc_auc_ovr(y_true, y_pred_proba, **kwargs):\n",
    "#     binary_labels = label_binarize(y_true, classes=np.unique(y_true))\n",
    "#     ovr_auc = roc_auc_score(binary_labels, y_pred_proba, average='macro', multi_class='ovr')\n",
    "#     return ovr_auc\n",
    "\n",
    "# # Convert custom metrics into an AutoGluon usable rater\n",
    "# custom_auc_scorer = make_scorer(name='roc_auc_ovr', score_func=custom_roc_auc_ovr, greater_is_better=True, needs_proba=True)\n",
    "# from autogluon.tabular import TabularPredictor\n",
    "# import pandas as pd\n",
    "\n",
    "# # 初始化一个空的 DataFrame 来存储每个折次的 leaderboard\n",
    "# leaderboards = []\n",
    "\n",
    "# # 循环加载每个折次的模型并获取其 leaderboard\n",
    "# for fold in range(10):\n",
    "#     model_path = f'/home/tailab/se/solarelastosis_v1/code/solar_elastosis_data_processor/autogluon_three_ways_fold_{fold}_model'\n",
    "#     predictor = TabularPredictor.load(model_path)\n",
    "#     leaderboard = predictor.leaderboard(silent=True)\n",
    "#     leaderboard['fold'] = fold  # 添加折次信息，方便后续分析\n",
    "#     leaderboards.append(leaderboard)\n",
    "\n",
    "# # 将所有折次的 leaderboard 合并为一个 DataFrame\n",
    "# combined_leaderboard = pd.concat(leaderboards, ignore_index=True)\n",
    "\n",
    "# # 过滤掉非数值列，仅对数值列计算平均得分\n",
    "# numeric_columns = combined_leaderboard.select_dtypes(include=['number']).columns\n",
    "# average_leaderboard = combined_leaderboard.groupby('model')[numeric_columns].mean().reset_index()\n",
    "\n",
    "# # 按照验证集分数进行排序\n",
    "# average_leaderboard = average_leaderboard.sort_values(by='score_val', ascending=False)\n",
    "\n",
    "# # 输出平均 leaderboard\n",
    "# print(average_leaderboard)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "import regex as re\n",
    "import numpy as np\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gem_csv_path = \"/home/tailab/se/data/Gem_processed_new.csv\"\n",
    "pt_path = \"/home/tailab/se/data/resnet_features_solarelastosis/tumor_subtyping_resnet_features/pt_files/\"\n",
    "h5_path = \"/home/tailab/se/data/resnet_features_solarelastosis/tumor_subtyping_resnet_features/h5_files/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(gem_csv_path)\n",
    "\n",
    "# Specify the indices of continuous columns from the original DataFrame (6th, 7th, and 34th columns)\n",
    "continuous_indices = [5, 6, 33]  # Adjusted for zero-indexing\n",
    "\n",
    "# Extract the names of continuous columns based on original indices before dropping any columns\n",
    "continuous_columns = [\n",
    "    df.columns[idx] for idx in continuous_indices if idx < df.shape[1]\n",
    "]\n",
    "df.drop_duplicates(subset =['Deepest Lesion (Recent & Previous) blgm'],keep='first',inplace=True)\n",
    "file_ref = df['Deepest Lesion (Recent & Previous) blgm'].values.tolist()\n",
    "target_ref = dict(zip(df['Deepest Lesion (Recent & Previous) blgm'].values.tolist(), df['Deepest Lesion (Recent & Previous) SOLAREL'].values.tolist()))\n",
    "# List of columns to remove after identifying continuous columns\n",
    "columns_to_remove = [\n",
    "    'MRN', 'status', 'Indicator for being a control to case patient', \n",
    "    'Deepest Lesion (Recent & Previous) SOLAREL', \n",
    "    'Deepest Lesion (Recent & Previous) LYMPHCT_new',\n",
    "    'blgm_1', 'blgm_2', 'Deepest Lesion (Recent & Previous) LYMPHCT', \n",
    "    'Deepest Lesion (Recent & Previous) Solar_new',\n",
    "    'Solar Elastosis - Control/Case Defining Lesion - Most Recent Dx', \n",
    "    'Solar Elastosis Lesion 1 recoded with absent=0', \n",
    "    'ulc1', 'ulc2', 'Pathologist performing Slide Review - Control/Case Defining Lesion - Most Recent Dx',\n",
    "    'Deepest Lesion (Recent & Previous) reviewed?', \n",
    "    'Dx most recent - calculated from DOB and path report'\n",
    "]\n",
    "\n",
    "# Drop columns that are present in the DataFrame\n",
    "present_columns_to_remove = [col for col in columns_to_remove if col in df.columns]\n",
    "refined_df = df.drop(present_columns_to_remove, axis=1)\n",
    "first_column = refined_df.pop('Deepest Lesion (Recent & Previous) blgm')\n",
    "# leave the columns still exists after dropping\n",
    "continuous_columns = [col for col in refined_df.columns if col in continuous_columns]\n",
    "# Identify categorical columns as those not in the continuous columns list\n",
    "categorical_columns = [col for col in refined_df.columns if col not in continuous_columns]\n",
    "\n",
    "# Final identified columns for categorical and continuous data\n",
    "final_categorical_columns = categorical_columns\n",
    "final_continuous_columns = continuous_columns\n",
    "\n",
    "# Display or use the identified categorical and continuous columns as needed\n",
    "print(\"Categorical Columns:\", final_categorical_columns)\n",
    "print(\"Continuous Columns:\", final_continuous_columns)\n",
    "\n",
    "\n",
    "refined_df.to_csv('refined_gem.csv')\n",
    "#columns, index = refined_df.columns, refined_df.index\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#refined_df = pd.DataFrame(StandardScaler().fit_transform(refined_df), columns=columns, index=index)\n",
    "data = refined_df\n",
    "all_columns = data.columns\n",
    "# # Drop the unnamed index column if present\n",
    "# if 'Unnamed: 0' in data.columns:\n",
    "#     data = data.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# # Threshold for determining initial categorical columns\n",
    "# categorical_threshold = 100  # Columns with unique values <= 100 will be considered initially as categorical\n",
    "\n",
    "# # Identify initial categorical and continuous columns\n",
    "# categorical_columns = data.columns[data.nunique() <= categorical_threshold]\n",
    "# continuous_columns = data.columns.difference(categorical_columns)\n",
    "\n",
    "# # Further refine categorical columns by ensuring they are integer-like\n",
    "# final_categorical_columns = []\n",
    "# final_continuous_columns = list(continuous_columns)  # Start with initially identified continuous columns\n",
    "\n",
    "# for col in categorical_columns:\n",
    "#     # Check if all values are integers or floats that are effectively integers (e.g., 1.0, 2.0)\n",
    "#     if np.issubdtype(data[col].dtype, np.number) and all(data[col] % 1 == 0):\n",
    "#         final_categorical_columns.append(col)\n",
    "#     else:\n",
    "#         final_continuous_columns.append(col)\n",
    "\n",
    "# # Convert categorical columns to integers if they are not already\n",
    "# for col in final_categorical_columns:\n",
    "#     data[col] = data[col].astype(int)\n",
    "#     data[col] = pd.Categorical(data[col]).codes\n",
    "\n",
    "# Splitting the data into final categorical and continuous sets\n",
    "categorical_data = data[final_categorical_columns]\n",
    "continuous_data = data[final_continuous_columns]\n",
    "\n",
    "# Normalizing continuous data\n",
    "mean = continuous_data.mean(axis=0)\n",
    "std = continuous_data.std(axis=0)\n",
    "continuous_data_normalized = (continuous_data - mean) / (std + 1e-9)\n",
    "# Combine categorical and normalized continuous data\n",
    "processed_data = pd.concat([categorical_data, continuous_data_normalized], axis=1)\n",
    "\n",
    "# Final processed data\n",
    "refined_df = processed_data\n",
    "\n",
    "#print(refined_df)\n",
    "\n",
    "\n",
    "print(\"Final input data shape:\", processed_data.shape)\n",
    "# for col in final_categorical_columns:\n",
    "#     unique_count = data[col].nunique()\n",
    "#     print(f'{unique_count},')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "# from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "# from pytorch_tabnet.augmentations import ClassificationSMOTE\n",
    "import scipy\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Step 1: Label Encoding for Categorical Features\n",
    "categorical_cols = refined_df.columns[:-3]  # Assuming last 3 columns are numerical\n",
    "# refined_df_categorical = refined_df[categorical_cols]\n",
    "refined_df_categorical = pd.get_dummies(refined_df[categorical_cols], columns=categorical_cols, dtype=int)\n",
    "refined_df_numerical = refined_df.iloc[:, -3:]  # Keeping numerical data\n",
    "\n",
    "# Combine encoded categorical data and normalized numerical data\n",
    "refined_df = pd.concat([refined_df_categorical, refined_df_numerical], axis=1)\n",
    "\n",
    "# Convert DataFrame to numpy array for TabNet\n",
    "data_np = refined_df.values\n",
    "\n",
    "data_pd = pd.DataFrame(data_np)\n",
    "data_pd.insert(0, 'Deepest Lesion (Recent & Previous) blgm', first_column)\n",
    "data_pd.dropna(inplace=True)\n",
    "\n",
    "# Prepare target labels based on refined_target_map\n",
    "labels = []\n",
    "filtered_indices = []\n",
    "\n",
    "# and  solar elastosis levels\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for idx, id in enumerate(data_pd['Deepest Lesion (Recent & Previous) blgm']):\n",
    "    if not pd.isna(id):\n",
    "        label = target_ref.get(id, None)  # Use .get() to avoid KeyErrors\n",
    "        if label == 3:\n",
    "            labels.append(2)  # 3 = Absent\"\n",
    "            filtered_indices.append(idx)\n",
    "        if label == 2:\n",
    "            labels.append(1)  # 2 = Marked\n",
    "            filtered_indices.append(idx)\n",
    "        elif label == 1:\n",
    "            labels.append(0)  # \"1 = Mild/moderate\n",
    "            filtered_indices.append(idx)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "# Filter data_np to keep only rows corresponding to selected labels\n",
    "data_np = data_np[filtered_indices]\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(data_np.shape, labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from autogluon.core.metrics import make_scorer\n",
    "\n",
    "# Convert data to DataFrame for AutoGluon\n",
    "train_df = pd.DataFrame(data_np)\n",
    "train_df['target'] = labels\n",
    "\n",
    "# Custom ROC AUC for binary classification\n",
    "def custom_roc_auc_ovr(y_true, y_pred_proba, **kwargs):\n",
    "    # ovr_auc = roc_auc_score(y_true, y_pred_proba[:, 1])  # Use the probability of the positive class\n",
    "    ovr_auc = roc_auc_score(y_true, y_pred_proba, multi_class='ovr')  # Use the probability of the positive class\n",
    "    return ovr_auc\n",
    "\n",
    "# Wrap the custom AUC function into an AutoGluon scorer\n",
    "custom_auc_scorer = make_scorer(\n",
    "    name='custom_roc_auc_ovr',\n",
    "    score_func=custom_roc_auc_ovr,\n",
    "    greater_is_better=True,\n",
    "    needs_proba=True\n",
    ")\n",
    "\n",
    "# Initialize KFold for cross-validation (10 folds)\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "embeddings_dict = {}\n",
    "test_results = []  # List to store the results of each fold (model, AUC, AUC-PR)\n",
    "\n",
    "# Perform 10-fold cross-validation: 8 folds for training, 1 fold for validation, and 1 fold for testing\n",
    "for fold, (train_val_index, test_index) in enumerate(kf.split(train_df)):\n",
    "    # Split into train+val and test sets\n",
    "    train_val_data = train_df.iloc[train_val_index]\n",
    "    test_data = train_df.iloc[test_index]\n",
    "\n",
    "    test_features = test_data.drop(columns=['target'])\n",
    "    test_labels = test_data['target'].values  # Ensure test_labels is a 1D numpy array\n",
    "\n",
    "    # Further split train_val_data into 8 folds for training and 1 fold for validation\n",
    "    inner_kf = KFold(n_splits=9, shuffle=True, random_state=fold)\n",
    "    train_index, val_index = next(inner_kf.split(train_val_data))\n",
    "\n",
    "    fold_train_data = train_val_data.iloc[train_index]\n",
    "    val_data = train_val_data.iloc[val_index]\n",
    "    \n",
    "    val_features = val_data.drop(columns=['target'])\n",
    "    val_labels = val_data['target'].values  # Ensure val_labels is a 1D numpy array\n",
    "\n",
    "     # Define model path for the current fold\n",
    "    model_path = f'/home/tailab/se/data/autoGulon_results/solar_elastosis_data_processor/threeway_fold_{fold}_model'\n",
    "\n",
    "    # Initialize and fit AutoGluon Tabular Predictor if no existing model is found\n",
    "    predictor = TabularPredictor(\n",
    "        label='target', \n",
    "        eval_metric=custom_auc_scorer,\n",
    "        path=model_path\n",
    "    )\n",
    "    predictor.fit(train_data=fold_train_data, time_limit=3600, presets='best_quality')\n",
    "\n",
    "    # Step 3: Evaluate all models on the validation set to select the best one based on AUC\n",
    "    model_names = predictor.get_model_names()  # Get all trained models\n",
    "    best_model_name = None\n",
    "    best_val_auc = -np.inf\n",
    "    for model in model_names:\n",
    "        val_pred_proba = predictor.predict_proba(val_features, model=model, as_pandas=False)\n",
    "        # auc_score_val = roc_auc_score(val_labels, val_pred_proba[:, 1])  # AUC for the positive class\n",
    "        auc_score_val = roc_auc_score(val_labels, val_pred_proba, multi_class='ovr')  # AUC for the positive class\n",
    "        \n",
    "        if auc_score_val > best_val_auc:\n",
    "            best_val_auc = auc_score_val\n",
    "            best_model_name = model\n",
    "\n",
    "    # Step 4: Use the best model (on validation) to predict on the test set\n",
    "    test_pred_proba = predictor.predict_proba(test_features, model=best_model_name, as_pandas=False)\n",
    "\n",
    "    # Calculate AUC and AUC-PR for the positive class on the test set\n",
    "    auc_score_test = roc_auc_score(test_labels, test_pred_proba[:, 1])  # AUC for the positive class\n",
    "    # auc_score_test = roc_auc_score(test_labels, test_pred_proba, multi_class='ovr')  # AUC for the positive class\n",
    "    aucpr_score_test = average_precision_score(test_labels, test_pred_proba[:, 1])  # AUC-PR for the positive class\n",
    "    # aucpr_score_test = average_precision_score(test_labels, test_pred_proba, average='macro')  # AUC-PR for the positive class\n",
    "\n",
    "    # Save the AUC and AUC-PR scores for the current fold along with the best model name\n",
    "    test_results.append({\n",
    "        'fold': fold,\n",
    "        'model_name': best_model_name,\n",
    "        'val_auc': best_val_auc,\n",
    "        'test_auc': auc_score_test,\n",
    "        'test_aucpr': aucpr_score_test\n",
    "    })\n",
    "\n",
    "    # Step 5: Extract features (embeddings) from the test set\n",
    "    for idx, embedding in zip(test_features.index, test_pred_proba):\n",
    "        embeddings_dict[idx] = embedding\n",
    "\n",
    "# Get the sorted indices of test_features\n",
    "sorted_indices = sorted(embeddings_dict.keys())\n",
    "\n",
    "# Reassemble embeddings in the sorted order\n",
    "final_embeddings = np.array([embeddings_dict[idx] for idx in sorted_indices])\n",
    "\n",
    "print(f\"Final embeddings shape: {final_embeddings.shape}\")\n",
    "\n",
    "# Convert test results to DataFrame and save to CSV\n",
    "test_results_df = pd.DataFrame(test_results)\n",
    "print(f\"Test Results for each fold:\\n{test_results_df}\")\n",
    "test_results_df.to_csv('test_results_with_models.csv', index=False)\n",
    "\n",
    "# Display final results\n",
    "leaderboard = predictor.leaderboard(silent=False)\n",
    "print(\"\\nLeaderboard of Models:\")\n",
    "print(leaderboard)\n",
    "\n",
    "# Save leaderboard to CSV\n",
    "leaderboard.to_csv('autogluon_leaderboard.csv', index=False)\n",
    "\n",
    "# Visualize the results\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='model', y='score_val', data=leaderboard, ci=None)\n",
    "plt.title('Validation Score by Model')\n",
    "plt.ylabel('Validation Score (AUC)')\n",
    "plt.xlabel('Model')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='model', y='fit_time', data=leaderboard, ci=None)\n",
    "plt.title('Training Time by Model')\n",
    "plt.ylabel('Training Time (seconds)')\n",
    "plt.xlabel('Model')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='model', y='pred_time_val', data=leaderboard, ci=None)\n",
    "plt.title('Prediction Time by Model')\n",
    "plt.ylabel('Prediction Time (seconds)')\n",
    "plt.xlabel('Model')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding part\n",
    "\n",
    "\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# from autogluon.tabular import TabularPredictor\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "# from autogluon.core.metrics import make_scorer\n",
    "\n",
    "# # Convert data to DataFrame for AutoGluon\n",
    "# train_df = pd.DataFrame(data_np)\n",
    "# train_df['target'] = labels\n",
    "\n",
    "# # Custom ROC AUC for binary classification\n",
    "# def custom_roc_auc_ovr(y_true, y_pred_proba, **kwargs):\n",
    "#     ovr_auc = roc_auc_score(y_true, y_pred_proba[:, 1])  # Use the probability of the positive class\n",
    "#     return ovr_auc\n",
    "\n",
    "# # Wrap the custom AUC function into an AutoGluon scorer\n",
    "# custom_auc_scorer = make_scorer(\n",
    "#     name='custom_roc_auc_ovr',\n",
    "#     score_func=custom_roc_auc_ovr,\n",
    "#     greater_is_better=True,\n",
    "#     needs_proba=True\n",
    "# )\n",
    "\n",
    "# # Initialize KFold for cross-validation (10 folds)\n",
    "# kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "# embeddings_dict = {}\n",
    "# test_results = []  # List to store the results of each fold (model, AUC, AUC-PR)\n",
    "\n",
    "# # Perform 10-fold cross-validation: 8 folds for training, 1 fold for validation, and 1 fold for testing\n",
    "# for fold, (train_val_index, test_index) in enumerate(kf.split(train_df)):\n",
    "#     # Split into train+val and test sets\n",
    "#     train_val_data = train_df.iloc[train_val_index]\n",
    "#     test_data = train_df.iloc[test_index]\n",
    "\n",
    "#     test_features = test_data.drop(columns=['target'])\n",
    "#     test_labels = test_data['target'].values  # Ensure test_labels is a 1D numpy array\n",
    "\n",
    "#     # Further split train_val_data into 8 folds for training and 1 fold for validation\n",
    "#     inner_kf = KFold(n_splits=9, shuffle=True, random_state=fold)\n",
    "#     train_index, val_index = next(inner_kf.split(train_val_data))\n",
    "\n",
    "#     fold_train_data = train_val_data.iloc[train_index]\n",
    "#     val_data = train_val_data.iloc[val_index]\n",
    "    \n",
    "#     val_features = val_data.drop(columns=['target'])\n",
    "#     val_labels = val_data['target'].values  # Ensure val_labels is a 1D numpy array\n",
    "\n",
    "#     # Step 2: Initialize AutoGluon Tabular Predictor and fit on training data\n",
    "#     predictor = TabularPredictor(\n",
    "#         label='target', \n",
    "#         eval_metric='roc_auc',   # Use the correct scorer\n",
    "#         path=f'marked_vs_mild_fold_{fold}_model'\n",
    "#     )\n",
    "\n",
    "#     # Fit the model on the training data (8/9)\n",
    "#     predictor.fit(train_data=fold_train_data, time_limit=3600, presets='best_quality')\n",
    "\n",
    "#     # Step 3: Evaluate all models on the validation set to select the best one based on AUC\n",
    "#     model_names = predictor.get_model_names()  # Get all trained models\n",
    "#     best_model_name = None\n",
    "#     best_val_auc = -np.inf\n",
    "#     for model in model_names:\n",
    "#         val_pred_proba = predictor.predict_proba(val_features, model=model, as_pandas=False)\n",
    "#         auc_score_val = roc_auc_score(val_labels, val_pred_proba[:, 1])  # AUC for the positive class\n",
    "        \n",
    "#         if auc_score_val > best_val_auc:\n",
    "#             best_val_auc = auc_score_val\n",
    "#             best_model_name = model\n",
    "\n",
    "#     # Step 4: Use the best model (on validation) to predict on the test set\n",
    "#     test_pred_proba = predictor.predict_proba(test_features, model=best_model_name, as_pandas=False)\n",
    "\n",
    "#     # Calculate AUC and AUC-PR for the positive class on the test set\n",
    "#     auc_score_test = roc_auc_score(test_labels, test_pred_proba[:, 1])  # AUC for the positive class\n",
    "#     aucpr_score_test = average_precision_score(test_labels, test_pred_proba[:, 1])  # AUC-PR for the positive class\n",
    "\n",
    "#     # Save the AUC and AUC-PR scores for the current fold along with the best model name\n",
    "#     test_results.append({\n",
    "#         'fold': fold,\n",
    "#         'model_name': best_model_name,\n",
    "#         'val_auc': best_val_auc,\n",
    "#         'test_auc': auc_score_test,\n",
    "#         'test_aucpr': aucpr_score_test\n",
    "#     })\n",
    "\n",
    "#     # Step 5: Extract features (embeddings) from the test set\n",
    "#     for idx, embedding in zip(test_features.index, test_pred_proba):\n",
    "#         embeddings_dict[idx] = embedding\n",
    "\n",
    "# # Get the sorted indices of test_features\n",
    "# sorted_indices = sorted(embeddings_dict.keys())\n",
    "\n",
    "# # Reassemble embeddings in the sorted order\n",
    "# final_embeddings = np.array([embeddings_dict[idx] for idx in sorted_indices])\n",
    "\n",
    "# print(f\"Final embeddings shape: {final_embeddings.shape}\")\n",
    "\n",
    "# # Convert test results to DataFrame and save to CSV\n",
    "# test_results_df = pd.DataFrame(test_results)\n",
    "# print(f\"Test Results for each fold:\\n{test_results_df}\")\n",
    "# test_results_df.to_csv('test_results_with_models.csv', index=False)\n",
    "\n",
    "# # Display final results\n",
    "# leaderboard = predictor.leaderboard(silent=False)\n",
    "# print(\"\\nLeaderboard of Models:\")\n",
    "# print(leaderboard)\n",
    "\n",
    "# # Save leaderboard to CSV\n",
    "# leaderboard.to_csv('autogluon_leaderboard.csv', index=False)\n",
    "\n",
    "# # Visualize the results\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# sns.barplot(x='model', y='score_val', data=leaderboard, ci=None)\n",
    "# plt.title('Validation Score by Model')\n",
    "# plt.ylabel('Validation Score (AUC)')\n",
    "# plt.xlabel('Model')\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# sns.barplot(x='model', y='fit_time', data=leaderboard, ci=None)\n",
    "# plt.title('Training Time by Model')\n",
    "# plt.ylabel('Training Time (seconds)')\n",
    "# plt.xlabel('Model')\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# sns.barplot(x='model', y='pred_time_val', data=leaderboard, ci=None)\n",
    "# plt.title('Prediction Time by Model')\n",
    "# plt.ylabel('Prediction Time (seconds)')\n",
    "# plt.xlabel('Model')\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_embeddings.shape)\n",
    "\n",
    "refined_df = pd.DataFrame(data=final_embeddings)\n",
    "\n",
    "refined_df.insert(0,'Deepest Lesion (Recent & Previous) blgm',first_column)\n",
    "print(refined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df.columns.to_list()))\n",
    "print(len(refined_df.columns.to_list()))\n",
    "print(refined_df.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_files = os.listdir(pt_path)\n",
    "h5_files = os.listdir(h5_path)\n",
    "file_map = {}\n",
    "h5_map ={}\n",
    "for file in pt_files:\n",
    "    file_number = int(re.findall(r'\\d+',file)[0])\n",
    "    file_map [file_number] = file \n",
    "    h5_map [file_number] = file.replace('.pt','.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(refined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenate = False\n",
    "no_match_refs = []\n",
    "refined_ptfile_map = {}\n",
    "refined_h5file_map ={}\n",
    "refined_target_map ={}\n",
    "\n",
    "tab_data = {}\n",
    "refined_file_ref =[]\n",
    "\n",
    "for ref in file_ref:\n",
    "    if ref in file_map.keys():\n",
    "        refined_h5file_map [ref] = h5_map[ref]\n",
    "        refined_ptfile_map [ref] = file_map[ref]\n",
    "        refined_target_map [ref] = target_ref[ref]\n",
    "        filtered_rows = refined_df[refined_df['Deepest Lesion (Recent & Previous) blgm'] == ref]\n",
    "        if not filtered_rows.empty:\n",
    "            #print(filtered_rows.values.tolist()[0][1:]) \n",
    "            tab_data[ref] = filtered_rows.values.tolist()[0][1:]\n",
    "            refined_file_ref.append(ref)\n",
    "        else:\n",
    "            print(f\"No match found for ref: {ref}\")\n",
    "            no_match_refs.append(ref)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(refined_ptfile_map))\n",
    "print(len(refined_target_map))\n",
    "print(len(tab_data))\n",
    "#refined_df.to_csv('/home/tailab/se/data/tumor_vs_normal_dummy_clean_tabular.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pt_path = \"/home/tailab/se/data/autoML_mild_vs_absent_features/pt_files/\"\n",
    "new_h5_path = \"/home/tailab/se/data/autoML_mild_vs_absent_features/h5_files/\"\n",
    "\n",
    "if not os.path.exists(new_pt_path):\n",
    "    os.makedirs(new_pt_path)\n",
    "if not os.path.exists(new_h5_path):\n",
    "    os.makedirs(new_h5_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_embeddings(embeddings, data):\n",
    "    embeddings = embeddings.cpu().detach().numpy()\n",
    "    data = np.array([data])\n",
    "    return torch.from_numpy(np.hstack((embeddings,np.broadcast_to(data,(embeddings.shape[0],data.shape[1])))))\n",
    "\n",
    "from tqdm import tqdm\n",
    "concatenate = True\n",
    "for ref in tqdm(refined_file_ref):\n",
    "    pt_embeddings = torch.load(os.path.join(pt_path,refined_ptfile_map[ref]))\n",
    "    temp_tab_data = tab_data[ref]\n",
    "    #print(len(temp_tab_data))\n",
    "    #continue\n",
    "    if concatenate:\n",
    "        concat_embeddings = append_embeddings(pt_embeddings,temp_tab_data)\n",
    "        concat_embeddings = concat_embeddings.float()\n",
    "    else:\n",
    "        concat_embeddings = torch.from_numpy(np.array([temp_tab_data]))\n",
    "        concat_embeddings = concat_embeddings.float()\n",
    "        #print(concat_embeddings.shape)\n",
    "        \n",
    "    torch.save(concat_embeddings,os.path.join(new_pt_path,refined_ptfile_map[ref]))\n",
    "    shutil.copy(os.path.join(h5_path,refined_h5file_map[ref]),os.path.join(new_h5_path, refined_h5file_map[ref]))\n",
    "\n",
    " \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_target_df = pd.DataFrame(columns=['case_id','slide_id','label'])\n",
    "# {'subtype_1':0, 'subtype_2':1, 'subtype_3':2}\n",
    "# for ref in refined_file_ref:\n",
    "#     label = refined_target_map[ref]\n",
    "#     if label == 1:\n",
    "#         label = 'mild'\n",
    "#     elif label == 3:\n",
    "#         label = 'absent'\n",
    "#     else:\n",
    "#         #label = \"subtype_1\"\n",
    "#         continue\n",
    "for ref in refined_file_ref:\n",
    "    label = refined_target_map[ref]\n",
    "    if label == 3:\n",
    "        label = 'subtype_3'\n",
    "    elif label == 1:\n",
    "        label = 'subtype_1'\n",
    "    elif label == 2:\n",
    "        label = 'subtype_2'\n",
    "    else:\n",
    "        #label = \"subtype_1\"\n",
    "        continue\n",
    "    new_target_df=new_target_df._append({'case_id': ref, 'slide_id':refined_h5file_map[ref].replace('.h5',''),'label':label},ignore_index =True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_target_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_target_df = new_target_df[~new_target_df['case_id'].isin(no_match_refs)]\n",
    "new_target_df.to_csv(\"/home/tailab/se/data/tumor_vs_normal_mild_vs_absent.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_target_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Deepest Lesion (Recent & Previous) Solar_new'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
